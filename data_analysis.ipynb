{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####   RUN THIS CELL FIRST!   #####\n",
    "##### IMPORTS ALL REQUIREMENTS #####\n",
    "#####   & INCLUDES CONSTANTS   #####\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scipy.stats import pearsonr\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis Notebook\n",
    "\n",
    "## Introduction\n",
    "\n",
    "write stuff here on what is being done here\n",
    "\n",
    "## Todo\n",
    "\n",
    "1. Create table on mean, std, and other metrics for each demographics question.\n",
    "\n",
    "2. Create a breakdown of overall performance on how people performed on the task.\n",
    "\n",
    "3. Do an analysis on how different categories (poem, article, etc.) affected performance.\n",
    "\n",
    "4. Do an analysis of how people performed based on prior knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Data loading\n",
    "\n",
    "In this section, we are loading the data and parsing it so that we can use it in the data analysis section. We are getting rid of all the unnecessary metadata that qualtrics includes for each response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Helper Functions #####\n",
    "def parse_passage_response(x: str) -> int:\n",
    "    parse_dict = {\n",
    "        'Human Written': 0,\n",
    "        'AI Generated': 1\n",
    "    }\n",
    "    \n",
    "    return parse_dict.get(x, 0)\n",
    "\n",
    "def parse_sf1_response(x: str) -> int:\n",
    "    parse_dict = {\n",
    "        '0': 1,\n",
    "        '1': 2,\n",
    "        '2': 3,\n",
    "        '3': 4,\n",
    "        '4+': 5,\n",
    "    }\n",
    "    \n",
    "    return parse_dict.get(x, 1)\n",
    "\n",
    "def parse_sf2_response(x: str) -> int:\n",
    "    parse_dict = {\n",
    "        'Rarely or never': 1,\n",
    "        'A few times a month': 2,\n",
    "        'Once a week': 3,\n",
    "        'Several times a week': 4,\n",
    "        'Daily': 5,\n",
    "    }\n",
    "    \n",
    "    return parse_dict.get(x, 1)\n",
    "\n",
    "def parse_edu_response(x: str) -> int:\n",
    "    parse_dict = {\n",
    "        'High school diploma or GED': 1,\n",
    "        'Some college, but no degree': 2,\n",
    "        'Associate Degree': 3,\n",
    "        'Bachelor\\'s Degree': 4,\n",
    "        'Master\\'s Degree or higher education': 5,\n",
    "        'Other (Please fill in)': 6,\n",
    "        'Prefer not to say': 0\n",
    "    }\n",
    "    \n",
    "    return parse_dict.get(x, 0)\n",
    "\n",
    "def parse_ta_response(x: str) -> int:\n",
    "    if x == 'No':\n",
    "        return 0\n",
    "    return 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Group 6 Questionnaire (Broad)_November 15, 2023_17.25.tsv', 'Group 6 Questionnaire (Class)_November 15, 2023_19.26 - Copy (2).tsv', 'Group 6 Questionnaire (Class)_November 15, 2023_19.26 - Copy.tsv', 'Group 6 Questionnaire (Class)_November 15, 2023_19.26.tsv']\n",
      "Group 6 Questionnaire (Broad)_November 15, 2023_17.25.tsv\n",
      "Group 6 Questionnaire (Class)_November 15, 2023_19.26 - Copy (2).tsv\n",
      "Group 6 Questionnaire (Class)_November 15, 2023_19.26 - Copy.tsv\n",
      "Group 6 Questionnaire (Class)_November 15, 2023_19.26.tsv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duration (in seconds)</th>\n",
       "      <th>Finished</th>\n",
       "      <th>RecordedDate</th>\n",
       "      <th>ResponseId</th>\n",
       "      <th>ID</th>\n",
       "      <th>Consent</th>\n",
       "      <th>SF1_1</th>\n",
       "      <th>SF1_2</th>\n",
       "      <th>SF1_3</th>\n",
       "      <th>SF2_1</th>\n",
       "      <th>SF2_2</th>\n",
       "      <th>SF2_3</th>\n",
       "      <th>SF2_4</th>\n",
       "      <th>SF2_5</th>\n",
       "      <th>SF2_6</th>\n",
       "      <th>SF2_7</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Education_7_TEXT</th>\n",
       "      <th>Major</th>\n",
       "      <th>TA Exp</th>\n",
       "      <th>TA Exp_1_TEXT</th>\n",
       "      <th>HU-S3</th>\n",
       "      <th>AI-S1</th>\n",
       "      <th>HU-P2</th>\n",
       "      <th>AI-P1</th>\n",
       "      <th>HU-N2</th>\n",
       "      <th>AI-N1</th>\n",
       "      <th>HU-W2</th>\n",
       "      <th>AI-W3</th>\n",
       "      <th>Strategy</th>\n",
       "      <th>Patterns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>451</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-11-13 19:28:54</td>\n",
       "      <td>R_3h0H4nneVVU8gyp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AI Generated text has a cadence to it that's v...</td>\n",
       "      <td>Human text reads like it's describing a scene ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>396</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-11-13 19:30:57</td>\n",
       "      <td>R_1ClQwZC5Sjv9rSB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I tried to look for specific patterns in writi...</td>\n",
       "      <td>In my opinion, it just felt more life-like and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>411</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-11-13 19:50:04</td>\n",
       "      <td>R_1JCRIPGTmHEbDPu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Creative Writing</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I mostly just looked for lines that felt wrong...</td>\n",
       "      <td>\"The AI, in my opinion, used more details. How...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>445</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-11-13 19:50:48</td>\n",
       "      <td>R_2D5IQXnVn1RqoF7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Robotics Engineering</td>\n",
       "      <td>1</td>\n",
       "      <td>Program Aide Summer camp</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>If it cussed then it was a human because I can...</td>\n",
       "      <td>I think the ones i marked AI sounded too formal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1111</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-11-13 20:06:54</td>\n",
       "      <td>R_VKdXjaegc3N4i6R</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>1</td>\n",
       "      <td>CS, Head TA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I looked for tone and mistakes. I feel like sm...</td>\n",
       "      <td>It felt like most of these were human generate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>348</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-11-13 20:18:24</td>\n",
       "      <td>R_1ZAXPOXFRpVcmT7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Business Administration</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Forced formality and style</td>\n",
       "      <td>Forced formality and a lack of unique style fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>186</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-11-13 21:09:42</td>\n",
       "      <td>R_28V3ketyqTfKzNp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"HCDE \"</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>418</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-11-14 00:16:52</td>\n",
       "      <td>R_3eesWl2qJDirvqP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>599</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-11-14 00:18:34</td>\n",
       "      <td>R_3k85Klo00SV4cW9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Computer Science \"</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Formatting, and average sentence length. \"</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>617</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-11-14 09:55:26</td>\n",
       "      <td>R_2to22jnsqQmcUwj</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I look for cohesiveness and deeper meaning in ...</td>\n",
       "      <td>I assumed the one text with confusing word rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>329</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-11-15 13:27:11</td>\n",
       "      <td>R_21d3pRFIYkuo6iz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Information Security \"</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>629</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-11-15 15:26:09</td>\n",
       "      <td>R_3hDOdms3zbTUrBI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Finance/ Int’l Business \"</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>The words used and the number of commas</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>509</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-11-15 15:36:27</td>\n",
       "      <td>R_31nFcAKVwjKjvTy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Psychology \"</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Repetition or excessive/unnecessary use of ad...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>531</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-11-15 15:38:21</td>\n",
       "      <td>R_3gfLwlMXYN8Crux</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Computer Engineering</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I tried to see if the thoughts in the text wer...</td>\n",
       "      <td>The ones I flagged as AI I noticed a lot more ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>688</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-11-15 15:39:41</td>\n",
       "      <td>R_25WyGfZkykoYSGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Electrical Engineering</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I looked for patterns of writing that I've see...</td>\n",
       "      <td>As I said before, I think AI tends to give 3 a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>192</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-11-15 15:47:26</td>\n",
       "      <td>R_w6NkrbIP9SeqQj7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Not sure - went with my gut</td>\n",
       "      <td>\"I typically classified more long-winded respo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>765</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-11-10 10:51:30</td>\n",
       "      <td>R_3HRGzymG3R6uI9Z</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Psychology</td>\n",
       "      <td>1</td>\n",
       "      <td>General Psychology, Research Methods, Statisti...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I attempted to look for seemingly unhuman thin...</td>\n",
       "      <td>there were a couple repeats of words e.g., a r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>460</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-11-13 15:49:52</td>\n",
       "      <td>R_eV6HcVHIoX8dwWZ</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I have no clue. I mainly chose which one is hu...</td>\n",
       "      <td>For the poem, I think the AI tried hard to rhy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>765</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-11-10 10:51:30</td>\n",
       "      <td>R_3HRGzymG3R6uI9Z</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Psychology</td>\n",
       "      <td>1</td>\n",
       "      <td>General Psychology, Research Methods, Statisti...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I attempted to look for seemingly unhuman thin...</td>\n",
       "      <td>there were a couple repeats of words e.g., a r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>460</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-11-13 15:49:52</td>\n",
       "      <td>R_eV6HcVHIoX8dwWZ</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I have no clue. I mainly chose which one is hu...</td>\n",
       "      <td>For the poem, I think the AI tried hard to rhy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>765</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-11-10 10:51:30</td>\n",
       "      <td>R_3HRGzymG3R6uI9Z</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Psychology</td>\n",
       "      <td>1</td>\n",
       "      <td>General Psychology, Research Methods, Statisti...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I attempted to look for seemingly unhuman thin...</td>\n",
       "      <td>there were a couple repeats of words e.g., a r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>460</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-11-13 15:49:52</td>\n",
       "      <td>R_eV6HcVHIoX8dwWZ</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I have no clue. I mainly chose which one is hu...</td>\n",
       "      <td>For the poem, I think the AI tried hard to rhy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Duration (in seconds)  Finished         RecordedDate         ResponseId  \\\n",
       "0                     451      True  2023-11-13 19:28:54  R_3h0H4nneVVU8gyp   \n",
       "1                     396      True  2023-11-13 19:30:57  R_1ClQwZC5Sjv9rSB   \n",
       "2                     411      True  2023-11-13 19:50:04  R_1JCRIPGTmHEbDPu   \n",
       "3                     445      True  2023-11-13 19:50:48  R_2D5IQXnVn1RqoF7   \n",
       "4                    1111      True  2023-11-13 20:06:54  R_VKdXjaegc3N4i6R   \n",
       "5                     348      True  2023-11-13 20:18:24  R_1ZAXPOXFRpVcmT7   \n",
       "6                     186      True  2023-11-13 21:09:42  R_28V3ketyqTfKzNp   \n",
       "8                     418      True  2023-11-14 00:16:52  R_3eesWl2qJDirvqP   \n",
       "9                     599      True  2023-11-14 00:18:34  R_3k85Klo00SV4cW9   \n",
       "10                    617      True  2023-11-14 09:55:26  R_2to22jnsqQmcUwj   \n",
       "11                    329      True  2023-11-15 13:27:11  R_21d3pRFIYkuo6iz   \n",
       "12                    629      True  2023-11-15 15:26:09  R_3hDOdms3zbTUrBI   \n",
       "13                    509      True  2023-11-15 15:36:27  R_31nFcAKVwjKjvTy   \n",
       "14                    531      True  2023-11-15 15:38:21  R_3gfLwlMXYN8Crux   \n",
       "15                    688      True  2023-11-15 15:39:41  R_25WyGfZkykoYSGE   \n",
       "16                    192      True  2023-11-15 15:47:26  R_w6NkrbIP9SeqQj7   \n",
       "17                    765      True  2023-11-10 10:51:30  R_3HRGzymG3R6uI9Z   \n",
       "18                    460      True  2023-11-13 15:49:52  R_eV6HcVHIoX8dwWZ   \n",
       "19                    765      True  2023-11-10 10:51:30  R_3HRGzymG3R6uI9Z   \n",
       "20                    460      True  2023-11-13 15:49:52  R_eV6HcVHIoX8dwWZ   \n",
       "21                    765      True  2023-11-10 10:51:30  R_3HRGzymG3R6uI9Z   \n",
       "22                    460      True  2023-11-13 15:49:52  R_eV6HcVHIoX8dwWZ   \n",
       "\n",
       "      ID Consent  SF1_1  SF1_2  SF1_3  SF2_1  SF2_2  SF2_3  SF2_4  SF2_5  \\\n",
       "0    NaN     Yes      3      1      5      2      3      5      1      3   \n",
       "1    NaN     Yes      1      1      1      1      1      2      1      2   \n",
       "2    NaN     Yes      1      1      4      2      1      1      1      2   \n",
       "3    NaN     Yes      4      1      4      3      3      1      3      4   \n",
       "4    NaN     Yes      3      1      5      2      2      2      2      3   \n",
       "5    NaN     Yes      1      1      1      1      1      3      1      1   \n",
       "6    NaN     Yes      2      1      5      2      5      3      3      2   \n",
       "8    NaN     Yes      3      1      5      1      2      3      1      4   \n",
       "9    NaN     Yes      1      1      5      4      5      4      2      3   \n",
       "10   NaN     Yes      1      1      2      1      2      5      2      1   \n",
       "11   NaN     Yes      5      1      2      4      2      3      1      2   \n",
       "12   NaN     Yes      3      1      5      2      2      2      2      2   \n",
       "13   NaN     Yes      1      1      4      1      1      4      2      1   \n",
       "14   NaN     Yes      1      1      1      1      1      1      1      2   \n",
       "15   NaN     Yes      1      1      5      1      4      1      1      1   \n",
       "16   NaN     Yes      1      1      4      1      2      1      1      1   \n",
       "17  10.0     NaN      1      1      1      1      1      4      5      1   \n",
       "18  29.0     NaN      1      1      5      4      4      2      3      4   \n",
       "19  10.0     NaN      1      1      1      1      1      4      5      1   \n",
       "20  29.0     NaN      1      1      5      4      4      2      3      4   \n",
       "21  10.0     NaN      1      1      1      1      1      4      5      1   \n",
       "22  29.0     NaN      1      1      5      4      4      2      3      4   \n",
       "\n",
       "    SF2_6  SF2_7   Age  Education  Education_7_TEXT  \\\n",
       "0       1      4  20.0          2               NaN   \n",
       "1       2      2  19.0          1               NaN   \n",
       "2       2      2  22.0          2               NaN   \n",
       "3       4      1  21.0          2               NaN   \n",
       "4       1      1  21.0          4               NaN   \n",
       "5       1      1  23.0          4               NaN   \n",
       "6       1      1  29.0          5               NaN   \n",
       "8       1      2  23.0          1               NaN   \n",
       "9       3      1  31.0          4               NaN   \n",
       "10      2      2  27.0          5               NaN   \n",
       "11      1      1  26.0          4               NaN   \n",
       "12      1      3  22.0          2               NaN   \n",
       "13      2      1  21.0          2               NaN   \n",
       "14      1      1  21.0          3               NaN   \n",
       "15      1      1  21.0          4               NaN   \n",
       "16      1      1  22.0          1               NaN   \n",
       "17      2      1  34.0          5               NaN   \n",
       "18      5      1  22.0          1               NaN   \n",
       "19      2      1  34.0          5               NaN   \n",
       "20      5      1  22.0          1               NaN   \n",
       "21      2      1  34.0          5               NaN   \n",
       "22      5      1  22.0          1               NaN   \n",
       "\n",
       "                         Major  TA Exp  \\\n",
       "0             Computer Science       0   \n",
       "1                          NaN       0   \n",
       "2             Creative Writing       0   \n",
       "3         Robotics Engineering       1   \n",
       "4             Computer Science       1   \n",
       "5      Business Administration       0   \n",
       "6                      \"HCDE \"       0   \n",
       "8                          NaN       0   \n",
       "9          \"Computer Science \"       0   \n",
       "10                 Engineering       0   \n",
       "11     \"Information Security \"       0   \n",
       "12  \"Finance/ Int’l Business \"       0   \n",
       "13               \"Psychology \"       0   \n",
       "14        Computer Engineering       0   \n",
       "15      Electrical Engineering       0   \n",
       "16                         NaN       0   \n",
       "17                  Psychology       1   \n",
       "18                         NaN       0   \n",
       "19                  Psychology       1   \n",
       "20                         NaN       0   \n",
       "21                  Psychology       1   \n",
       "22                         NaN       0   \n",
       "\n",
       "                                        TA Exp_1_TEXT  HU-S3  AI-S1  HU-P2  \\\n",
       "0                                                 NaN      0      0      0   \n",
       "1                                                 NaN      0      1      0   \n",
       "2                                                 NaN      0      0      1   \n",
       "3                            Program Aide Summer camp      0      1      0   \n",
       "4                                         CS, Head TA      0      0      0   \n",
       "5                                                 NaN      0      1      0   \n",
       "6                                                 NaN      0      1      1   \n",
       "8                                                 NaN      0      1      1   \n",
       "9                                                 NaN      0      1      0   \n",
       "10                                                NaN      0      1      0   \n",
       "11                                                NaN      1      0      1   \n",
       "12                                                NaN      0      1      1   \n",
       "13                                                NaN      0      0      0   \n",
       "14                                                NaN      0      0      1   \n",
       "15                                                NaN      0      1      1   \n",
       "16                                                NaN      1      1      0   \n",
       "17  General Psychology, Research Methods, Statisti...      0      1      0   \n",
       "18                                                NaN      0      0      0   \n",
       "19  General Psychology, Research Methods, Statisti...      0      1      0   \n",
       "20                                                NaN      0      0      0   \n",
       "21  General Psychology, Research Methods, Statisti...      0      1      0   \n",
       "22                                                NaN      0      0      0   \n",
       "\n",
       "    AI-P1  HU-N2  AI-N1  HU-W2  AI-W3  \\\n",
       "0       1      1      1      1      1   \n",
       "1       1      1      0      1      1   \n",
       "2       0      1      0      0      1   \n",
       "3       1      0      1      0      1   \n",
       "4       0      0      0      0      0   \n",
       "5       1      0      0      1      1   \n",
       "6       1      1      0      1      1   \n",
       "8       0      0      0      1      0   \n",
       "9       1      1      0      0      1   \n",
       "10      0      0      1      0      0   \n",
       "11      0      1      1      0      0   \n",
       "12      0      1      1      0      1   \n",
       "13      0      0      1      0      1   \n",
       "14      1      0      0      1      1   \n",
       "15      0      0      1      1      1   \n",
       "16      0      1      0      1      1   \n",
       "17      1      0      0      1      1   \n",
       "18      0      1      1      0      1   \n",
       "19      1      0      0      1      1   \n",
       "20      0      1      1      0      1   \n",
       "21      1      0      0      1      1   \n",
       "22      0      1      1      0      1   \n",
       "\n",
       "                                             Strategy  \\\n",
       "0   AI Generated text has a cadence to it that's v...   \n",
       "1   I tried to look for specific patterns in writi...   \n",
       "2   I mostly just looked for lines that felt wrong...   \n",
       "3   If it cussed then it was a human because I can...   \n",
       "4   I looked for tone and mistakes. I feel like sm...   \n",
       "5                          Forced formality and style   \n",
       "6                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9         \"Formatting, and average sentence length. \"   \n",
       "10  I look for cohesiveness and deeper meaning in ...   \n",
       "11                                                NaN   \n",
       "12            The words used and the number of commas   \n",
       "13  \"Repetition or excessive/unnecessary use of ad...   \n",
       "14  I tried to see if the thoughts in the text wer...   \n",
       "15  I looked for patterns of writing that I've see...   \n",
       "16                        Not sure - went with my gut   \n",
       "17  I attempted to look for seemingly unhuman thin...   \n",
       "18  I have no clue. I mainly chose which one is hu...   \n",
       "19  I attempted to look for seemingly unhuman thin...   \n",
       "20  I have no clue. I mainly chose which one is hu...   \n",
       "21  I attempted to look for seemingly unhuman thin...   \n",
       "22  I have no clue. I mainly chose which one is hu...   \n",
       "\n",
       "                                             Patterns  \n",
       "0   Human text reads like it's describing a scene ...  \n",
       "1   In my opinion, it just felt more life-like and...  \n",
       "2   \"The AI, in my opinion, used more details. How...  \n",
       "3     I think the ones i marked AI sounded too formal  \n",
       "4   It felt like most of these were human generate...  \n",
       "5   Forced formality and a lack of unique style fe...  \n",
       "6                                                 NaN  \n",
       "8                                                 NaN  \n",
       "9                                                 NaN  \n",
       "10  I assumed the one text with confusing word rep...  \n",
       "11                                                NaN  \n",
       "12                                                NaN  \n",
       "13                                                 No  \n",
       "14  The ones I flagged as AI I noticed a lot more ...  \n",
       "15  As I said before, I think AI tends to give 3 a...  \n",
       "16  \"I typically classified more long-winded respo...  \n",
       "17  there were a couple repeats of words e.g., a r...  \n",
       "18  For the poem, I think the AI tried hard to rhy...  \n",
       "19  there were a couple repeats of words e.g., a r...  \n",
       "20  For the poem, I think the AI tried hard to rhy...  \n",
       "21  there were a couple repeats of words e.g., a r...  \n",
       "22  For the poem, I think the AI tried hard to rhy...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load df\n",
    "data_path = Path('./data/')\n",
    "tsv_files = os.listdir(data_path)\n",
    "\n",
    "print(tsv_files)\n",
    "\n",
    "dfs = []\n",
    "starting_value = 0\n",
    "for tsv_file in tsv_files:\n",
    "    print(tsv_file)\n",
    "    new_df = pd.read_csv(data_path/tsv_file, sep='\\t', encoding='UTF-16', quoting=3, skiprows=[1,2])\n",
    "    new_df.index = np.arange(starting_value, starting_value+len(new_df))\n",
    "    starting_value += len(new_df)\n",
    "    dfs.append(new_df)\n",
    "\n",
    "df = pd.concat(dfs)\n",
    "\n",
    "# Removes extra metadata from dataframe\n",
    "columns_to_keep = [\"Duration (in seconds)\", \"Finished\", \"RecordedDate\", \"ResponseId\", \"ID\", \"Consent\", \"SF1_1\", \"SF1_2\", \"SF1_3\", \"SF2_1\", \"SF2_2\", \"SF2_3\", \"SF2_4\", \"SF2_5\", \"SF2_6\", \"SF2_7\", \"Age\", \"Education\", \"Education_7_TEXT\", \"Major\", \"TA Exp\", \"TA Exp_1_TEXT\", \"HU-S3\", \"AI-S1\", \"HU-P2\", \"AI-P1\", \"HU-N2\", \"AI-N1\", \"HU-W2\", \"AI-W3\", \"Strategy\", \"Patterns\"]\n",
    "df = df[columns_to_keep].reset_index(drop=True) \n",
    "\n",
    "# Keep finished responses\n",
    "df = df[(pd.notna(df['ID'])) | (df['Consent']=='Yes')]\n",
    "df = df[df['Finished']==True]\n",
    "\n",
    "\n",
    "# Columns for reference\n",
    "sf1_cols = [x for x in df.columns if 'SF1' in x]\n",
    "sf2_cols = [x for x in df.columns if 'SF2' in x]\n",
    "passage_cols = [x for x in df.columns if x[:2] in ('AI', 'HU')]\n",
    "true_answers = [0 if x[:2] == 'HU' else 1 for x in passage_cols]\n",
    "\n",
    "# Parsing responses\n",
    "df[sf1_cols] = df[sf1_cols].map(parse_sf1_response)\n",
    "df[sf2_cols] = df[sf2_cols].map(parse_sf2_response)\n",
    "df[passage_cols] = df[passage_cols].map(parse_passage_response)\n",
    "df['Education'] = df['Education'].map(parse_edu_response)\n",
    "df['TA Exp'] = df['TA Exp'].map(parse_ta_response)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SF1_AVG</th>\n",
       "      <th>SF2_AI_AVG</th>\n",
       "      <th>SF2_HU_AVG</th>\n",
       "      <th>TA Exp</th>\n",
       "      <th>ANS_TOTAL</th>\n",
       "      <th>ANS_STORY</th>\n",
       "      <th>ANS_POEM</th>\n",
       "      <th>ANS_NEWS</th>\n",
       "      <th>ANS_WIKI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.333333</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.333333</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.333333</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.333333</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SF1_AVG  SF2_AI_AVG  SF2_HU_AVG  TA Exp  ANS_TOTAL  ANS_STORY  ANS_POEM  \\\n",
       "0   3.000000         2.5         2.8       0          5          1         2   \n",
       "1   1.000000         1.0         1.8       0          5          2         2   \n",
       "2   2.000000         1.5         1.6       0          3          1         0   \n",
       "3   3.000000         3.0         2.6       1          8          2         2   \n",
       "4   3.000000         2.0         1.8       1          4          1         1   \n",
       "5   1.000000         1.0         1.4       0          6          2         2   \n",
       "6   2.666667         3.5         2.0       0          4          2         1   \n",
       "8   3.000000         1.5         2.2       0          3          2         0   \n",
       "9   2.333333         4.5         2.6       0          6          2         2   \n",
       "10  1.333333         1.5         2.4       0          6          2         1   \n",
       "11  2.666667         3.0         1.6       0          2          0         0   \n",
       "12  3.000000         2.0         2.0       0          5          2         0   \n",
       "13  2.000000         1.0         2.0       0          6          1         1   \n",
       "14  1.000000         1.0         1.2       0          4          1         1   \n",
       "15  2.333333         2.5         1.0       0          5          2         0   \n",
       "16  2.000000         1.5         1.0       0          3          1         1   \n",
       "17  1.000000         1.0         2.6       1          6          2         2   \n",
       "18  2.333333         4.0         3.0       0          5          1         1   \n",
       "19  1.000000         1.0         2.6       1          6          2         2   \n",
       "20  2.333333         4.0         3.0       0          5          1         1   \n",
       "21  1.000000         1.0         2.6       1          6          2         2   \n",
       "22  2.333333         4.0         3.0       0          5          1         1   \n",
       "\n",
       "    ANS_NEWS  ANS_WIKI  \n",
       "0          1         1  \n",
       "1          0         1  \n",
       "2          0         2  \n",
       "3          2         2  \n",
       "4          1         1  \n",
       "5          1         1  \n",
       "6          0         1  \n",
       "8          1         0  \n",
       "9          0         2  \n",
       "10         2         1  \n",
       "11         1         1  \n",
       "12         1         2  \n",
       "13         2         2  \n",
       "14         1         1  \n",
       "15         2         1  \n",
       "16         0         1  \n",
       "17         1         1  \n",
       "18         1         2  \n",
       "19         1         1  \n",
       "20         1         2  \n",
       "21         1         1  \n",
       "22         1         2  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregating scores for Source Familiarity\n",
    "df['SF1_AVG'] = df[sf1_cols].mean(axis=1)\n",
    "df['SF2_AI_AVG'] = df[sf2_cols[:2]].mean(axis=1)\n",
    "df['SF2_HU_AVG'] = df[sf2_cols[2:]].mean(axis=1)\n",
    "\n",
    "# Aggregating scores for passsages\n",
    "df['ANS_TOTAL'] = (df[passage_cols] == true_answers).sum(axis=1)\n",
    "df['ANS_STORY'] = (df[passage_cols[0:2]] == true_answers[0:2]).sum(axis=1)\n",
    "df['ANS_POEM'] = (df[passage_cols[2:4]] == true_answers[2:4]).sum(axis=1)\n",
    "df['ANS_NEWS'] = (df[passage_cols[4:6]] == true_answers[4:6]).sum(axis=1)\n",
    "df['ANS_WIKI'] = (df[passage_cols[6:8]] == true_answers[6:8]).sum(axis=1)\n",
    "\n",
    "agg_sf_list = [df['SF1_AVG'], df['SF2_AI_AVG'], df['SF2_HU_AVG']]\n",
    "answer_list = [df['ANS_TOTAL'], df['ANS_STORY'], df['ANS_POEM'], df['ANS_NEWS'], df['ANS_WIKI']]\n",
    "data_cols = ['SF1_AVG', 'SF2_AI_AVG', 'SF2_HU_AVG', 'TA Exp', 'ANS_TOTAL', 'ANS_STORY', 'ANS_POEM', 'ANS_NEWS', 'ANS_WIKI']\n",
    "\n",
    "df[data_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: SF1_AVG, Mean: 2.06, Std: 0.78\n",
      "Column: SF2_AI_AVG, Mean: 2.18, Std: 1.20\n",
      "Column: SF2_HU_AVG, Mean: 2.13, Std: 0.64\n",
      "Column: ANS_TOTAL, Mean: 4.91, Std: 1.38\n",
      "Column: ANS_STORY, Mean: 1.50, Std: 0.60\n",
      "Column: ANS_POEM, Mean: 1.14, Std: 0.77\n",
      "Column: ANS_NEWS, Mean: 0.95, Std: 0.65\n",
      "Column: ANS_WIKI, Mean: 1.32, Std: 0.57\n",
      "\n",
      "Correlation Matrix w/ Stastical Signicance (*=0.05, **=0.01, ***=0.001):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SF1_AVG</th>\n",
       "      <th>SF2_AI_AVG</th>\n",
       "      <th>SF2_HU_AVG</th>\n",
       "      <th>TA Exp</th>\n",
       "      <th>ANS_TOTAL</th>\n",
       "      <th>ANS_STORY</th>\n",
       "      <th>ANS_POEM</th>\n",
       "      <th>ANS_NEWS</th>\n",
       "      <th>ANS_WIKI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SF1_AVG</th>\n",
       "      <td>1.0***</td>\n",
       "      <td>0.6**</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>-0.46*</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SF2_AI_AVG</th>\n",
       "      <td>0.6**</td>\n",
       "      <td>1.0***</td>\n",
       "      <td>0.45*</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.5*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SF2_HU_AVG</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.45*</td>\n",
       "      <td>1.0***</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.48*</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TA Exp</th>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.0***</td>\n",
       "      <td>0.44*</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.48*</td>\n",
       "      <td>0.21</td>\n",
       "      <td>-0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANS_TOTAL</th>\n",
       "      <td>-0.26</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.48*</td>\n",
       "      <td>0.44*</td>\n",
       "      <td>1.0***</td>\n",
       "      <td>0.58**</td>\n",
       "      <td>0.68***</td>\n",
       "      <td>0.47*</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANS_STORY</th>\n",
       "      <td>-0.27</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.58**</td>\n",
       "      <td>1.0***</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANS_POEM</th>\n",
       "      <td>-0.46*</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.48*</td>\n",
       "      <td>0.68***</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.0***</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANS_NEWS</th>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.47*</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>1.0***</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANS_WIKI</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5*</td>\n",
       "      <td>0.35</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.34</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.0***</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           SF1_AVG SF2_AI_AVG SF2_HU_AVG  TA Exp ANS_TOTAL ANS_STORY ANS_POEM  \\\n",
       "SF1_AVG     1.0***      0.6**       0.13   -0.19     -0.26     -0.27   -0.46*   \n",
       "SF2_AI_AVG   0.6**     1.0***      0.45*   -0.27      -0.0     -0.23     -0.1   \n",
       "SF2_HU_AVG    0.13      0.45*     1.0***    0.27     0.48*       0.1      0.4   \n",
       "TA Exp       -0.19      -0.27       0.27  1.0***     0.44*      0.28    0.48*   \n",
       "ANS_TOTAL    -0.26       -0.0      0.48*   0.44*    1.0***    0.58**  0.68***   \n",
       "ANS_STORY    -0.27      -0.23        0.1    0.28    0.58**    1.0***     0.36   \n",
       "ANS_POEM    -0.46*       -0.1        0.4   0.48*   0.68***      0.36   1.0***   \n",
       "ANS_NEWS      0.07      -0.11       0.13    0.21     0.47*      0.06    -0.08   \n",
       "ANS_WIKI       0.2       0.5*       0.35   -0.12      0.34     -0.21      0.0   \n",
       "\n",
       "           ANS_NEWS ANS_WIKI  \n",
       "SF1_AVG        0.07      0.2  \n",
       "SF2_AI_AVG    -0.11     0.5*  \n",
       "SF2_HU_AVG     0.13     0.35  \n",
       "TA Exp         0.21    -0.12  \n",
       "ANS_TOTAL     0.47*     0.34  \n",
       "ANS_STORY      0.06    -0.21  \n",
       "ANS_POEM      -0.08      0.0  \n",
       "ANS_NEWS     1.0***     0.04  \n",
       "ANS_WIKI       0.04   1.0***  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for sf_col in agg_sf_list:\n",
    "    name = sf_col.name\n",
    "    mean = sf_col.mean()\n",
    "    std = sf_col.std()\n",
    "    print(f'Column: {name}, Mean: {mean:.2f}, Std: {std:.2f}')\n",
    "\n",
    "for ans_col in answer_list:\n",
    "    name = ans_col.name\n",
    "    mean = ans_col.mean()\n",
    "    std = ans_col.std()\n",
    "    print(f'Column: {name}, Mean: {mean:.2f}, Std: {std:.2f}')\n",
    "\n",
    "# https://stackoverflow.com/questions/25571882/pandas-columns-correlation-with-statistical-significance\\\n",
    "rho = df[data_cols].corr()\n",
    "pval = df[data_cols].corr(method=lambda x, y: pearsonr(x, y)[1]) - np.eye(*rho.shape)\n",
    "p = pval.map(lambda x: ''.join(['*' for t in [.05, .01, .001] if x<=t]))\n",
    "corr_matrix_signifcance = rho.round(2).astype(str) + p\n",
    "\n",
    "\n",
    "\n",
    "print('\\nCorrelation Matrix w/ Stastical Signicance (*=0.05, **=0.01, ***=0.001):')\n",
    "corr_matrix_signifcance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
